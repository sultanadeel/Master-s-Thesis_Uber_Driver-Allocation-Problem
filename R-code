
******* Preprocessing of the dataset ***********

 MyData <- read.csv(file="07_03_TestData.csv",stringsAsFactors = F)
 head(MyData)
 str(MyData)
 dim(MyData)
 MyData$pickup_date = as.Date(MyData$pickup_date, '%m/%d/%y')
library(lubridate)
 x=hms(MyData$pickup_time)
 MyData$Time_Period = hour(x) * 2 + ifelse((minute(x)-30)>0,2,0) + 
ifelse((minute(x)-30)<0,1,0)
MyData[order(as.Date(MyData$pickup_date, format="%m/%d/%y")),]
 library(dplyr)
MyData$geo_hash1 = str_sub(MyData$geo_hash,1,5)
length(unique(MyData[["driver_uuid"]]))
 MyData <- MyData%>%
     mutate(Driver_ID = group_indices(., driver_uuid))
 days = group_by(MyData,geo_hash1, pickup_date, Time_Period)
 requests = summarize(days, Total_num_of_requests=dplyr::n())
requests = as.data.frame(requests)
dfnew <- requests[,c(1,2,3,4)]
df3 = ddply(dfnew, "pickup_date", summarise, Time_Period =seq(1, 48))
z = merge(requests,df3, all.y=TRUE)
>write.csv(z, "data1.csv", na = "0")
> df8 <- read.csv(file="data1.csv",stringsAsFactors = F,row.names=1)
> length(unique(df8[["Driver_ID"]]))
> length(unique(df8[["Time_Period"]]))
> length(unique(df8[["Total_num_of_requests"]]))
> df8$pickup_date = as.Date(df8$pickup_date, '%Y-%m-%d')
> newFrame <-aggregate(df8$Total_num_of_requests, 
 list(df8$pickup_date),mean)
>  newFrame <-aggregate(df8$Total_num_of_requests,
  list(df8$pickup_date,df8$Driver_ID),mean)
>  names(newFrame) <- c("pickup_date","Driver_id",
  "Total_num_of_requests")
> ggplot(newFrame, aes(x = newFrame$Group.1, y = newFrame$x)) +
 geom_point(size = 2,shape=19)
> ggplot(newFrame, aes(month, x)) + geom_line()
> bp= ggplot(data=newFrame, aes(x=factor(month),y=x))
> bp= ggplot(data=newtable, aes(x=factor(Driver_ID),y=avg))
> bp+geom_boxplot(fill='white',color="darkred")+xlab("Driver ID") +
 ylab("Total Revenue")+  theme(text = element_text(size=15))
 
> newFrame<- newFrame %>%
         mutate(year = year(Group.1))
>newFrame$day = strftime(newFrame$Group.1,'%A')
>newFrame$month = strftime(newFrame$Group.1,'%m')

*********Average Revenue for Geohashes*************

>df_freq=data.frame(table(MyData$geo_hash)) 
>df_aggr=aggregate(MyData$total, by=list(geo_hash=MyData$geo_hash), 
FUN=sum)
>df_aggr$freq=df_freq$Freq
>df_aggr$avg=df_aggr[,2] / df_aggr[,3] 
>min(df_aggr$avg)
>max(df_aggr$avg)
>newtable <- merge(MyData,df_aggr, by  = "geo_hash") 

>ggplot(drier_freq, aes(x = Var1, y = Freq)) + 
geom_col(fill='blue',color="black")+xlab("Driver ID") + 
ylab("Number of Trips")+  theme(text = element_text(size=15))

***********Average Revenue for Drivers*********

> df_freq2=data.frame(table(MyData$Driver_ID))
> df_aggr2=aggregate(MyData$total, by=list(Driver_ID=MyData$Driver_ID),
FUN=sum)
> df_aggr2$freq=df_freq2$Freq
> df_aggr2$avg=df_aggr2[,2] / df_aggr2[,3]

> ggplot(df_aggr2, aes(x = Driver_ID, y = avg)) +
geom_col(fill='yellow',color="black")+xlab("Driver ID") +
ylab("Average Revenue")+  theme(text = element_text(size=15),
panel.grid.major = element_blank(),                                                                     panel.grid.minor = element_blank(),panel.background =                                                   element_rect(fill = "transparent",colour = NA),                                                         plot.background = element_rect(fill = "transparent",colour = NA))+scale_x_continuous(breaks=seq(1,41,1))+scale_y_continuous(breaks=seq(0,100,10))

***********Visualizations using ggplot package********

>requets_month <- newFrame %>%
     group_by(month, year) %>%
     summarise(mean_requests = mean(x))
>requets_month %>%
     ggplot(aes(x = month, y = mean_requests)) +
     geom_bar(stat = "identity", fill = "darkorchid4") +
     facet_wrap(~ year, ncol=3) +
     labs(title = "Mean Monthly Requests",
          subtitle = "Data plotted by year",
          y = "Daily Total no.of Requests",
          x = "Month") + theme_bw(base_size = 15)
> requets_day <- newFrame %>%
          group_by(Group.2, day) %>%
          summarise(means_requests = mean(x))
> requets_day %>%
          ggplot(aes(x = Group.2, y = means_requests)) +
          geom_point(stat = "identity", fill = "darkorchid4") +
          facet_wrap(~ day, ncol = 3) +
          labs(title = "Mean Daily Requests",
                          subtitle = "Data plotted by day",
                          y = "Mean Daily Requests",
                          x = "Driver_id") + theme_bw(base_size = 15)
>newFrame %>%
ggplot(aes(x = Group.2, y = x)) +
      geom_bar(stat = "identity",color = "darkorchid4") +
      facet_wrap( ~ month, ncol = 3) +
      labs(title = "Monthly Total Request - Driver_id",
           subtitle = "Data plotted by month",
           y = "Total Requests",
           x = "Driver_id") + theme_bw(base_size = 15)
           
           
hist(newFrame$Driver_id)
library(plyr)
library(dplyr)
>geohash_vector <- pull(MyData, geo_hash1)
>u = unique(geohash_vector)
>MyData1 <- arrange(MyData,pickup_date)
values = seq(from = as.Date("2014-05-05"), to = as.Date("2017-03-07"), by = 'day')
>for(i in 1:length(u)){geohash <- u[i]
 mini.df <- cbind(data.frame(c(values)))
 mini.df = ddply(mini.df, "values", summarise, Time_Periods =seq(1,48))
 mini.df = cbind(mini.df, geohash)
 assign(paste("mini.df", i, sep="."), mini.df)
 }
>a=filter(z, geo_hash1== '9q8z')
>unique(MyData$geo_hash1)
>table(unlist(MyData$geo_hash1))
>colnames(mini.df.1)[colnames(mini.df.1)=="values"] <- "pickup_date"
>colnames(mini.df.1)[colnames(mini.df.1)=="Time_Periods"] <- "Time_Period"
>x= left_join(mini.df.1,a)
>x$geo_hash1=NULL
>write.csv(x, "mini.df.1.csv", na = "0")

***********Data Transformation********

>days1 = group_by(MyData2,geo_hash1, pickup_date, Time_Period)
>requests1 = summarize(days1, Total_num_of_requests=dplyr::n(), >Total_num_of_drivers=n_distinct(Driver_ID))
requests1 = as.data.frame(requests1)
>df_1 <- requests1[,c(1,2,3,5,6)]
>df_0 = ddply(df_1, .(geo_hash1,pickup_date), plyr::summarise, Time_Period =seq(1, 48))
>z1 = merge(df_1,df_0,all.y=TRUE)
>write.csv(z1, "data_1.csv", na = "0")
> df_8 <- read.csv(file="data_1.csv",stringsAsFactors = F,row.names=1)

***********Creating new variables Day,Month & Week*********

> df_8$Day = strftime(df_8$pickup_date,'%a')
> df_8$Day_month = strftime(df_8$pickup_date,'%d')
> df_8$Month = strftime(df_8$pickup_date,'%b')
> df_8$Week_of_Year = strftime(df_8$pickup_date,'%V')
> geohash1 = filter(df_8, geo_hash1=="9q8uv")
> df_8 <- df_8 %>% mutate_if(is.character,as.factor)
<<<<geocodes <- geocode(as.character(MyData2$dropoff_address))

***********Changing datatypes********

> df_8$Day <- factor(df_8$Day, levels=c("Mon", "Tue", "Wed", "Thu","Fri","Sat","Sun"))
> df_8$Month <- factor(df_8$Month, levels=c("Jan", "Feb", "Mar", "Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"))
> requests_day <- df_8 %>%
     group_by(Day) %>%
     summarise(means_requests = sum(Total_num_of_requests)/sum(Total_num_of_drivers))
> requests_day %>%
     ggplot(aes(x = Day, y = means_requests,group=1)) +
     geom_line() +geom_point(color = "darkorchid4")+
     labs(title = "Mean Daily Requests",
          subtitle = "Data plotted by day",
          y = "Tot.num of Requests/Tot.num of Drivers ",
          x = "Day") + theme_bw(base_size = 15)

> requests_month1 <- df_8 %>%
     group_by(Day_month,Month) %>%
     summarise(mean_requests = mean(Total_num_of_requests))
> requests_month1 %>%
     ggplot(aes(x = Day_month, y = mean_requests,group=1)) +
     geom_line(color = "darkorchid4") +geom_point(color = "darkorchid4")+
     facet_wrap(~ Month, ncol=3) +
     labs(title = "Mean Daily Requests",
          subtitle = "Data plotted by day",
         y = "Daily Total no.of Requests/Tot.num.of drivers",
          x = "Day_month") + theme_bw(base_size = 15)+
          theme_bw() +
    theme(axis.text.x = element_text(colour = "grey20", size = 10, angle = 90, hjust = 0.35, vjust = 0.35),
                        axis.text.y = element_text(colour = "grey20", size = 12),
          text = element_text(size = 16))
        

> requests_timeperiod <- df_8 %>%
     group_by(Time_Period) %>%
     summarise(mean_requests = sum(Total_num_of_requests)/sum(Total_num_of_drivers))
> requests_timeperiod %>%
     ggplot(aes(x = Time_Period, y = mean_requests,group=1)) +
     geom_line(color = "darkorchid4") +
     labs(title = "Mean Time_Period Requests",
          subtitle = "Data plotted for each time period",
          y = "Daily Total no.of Requests/Tot.num.of drivers",
          x = "Time_Period") + theme_bw(base_size = 15)
          
> requests_timeperiod <- df_8 %>%
     group_by(Time_Period,Day) %>%
     summarise(mean_requests = sum(Total_num_of_requests)/sum(Total_num_of_drivers))
     
> requests_timeperiod %>%
     ggplot(aes(x = Time_Period, y = mean_requests,group=1)) +
     geom_line(color = "darkorchid4") +geom_point(color = "darkorchid4")+
     facet_wrap(~ Day, ncol=3) +
     labs(title = "Mean Time_Period Requests by Day",
          subtitle = "Data plotted by day",
         y = "Daily Total no.of Requests/Tot.num.of drivers",
          x = "Time_Period") + theme_bw(base_size = 15)+
          theme_bw() +
    theme(axis.text.x = element_text(colour = "grey20", size = 10, angle = 90, hjust = 0.35, vjust = 0.35),
                        axis.text.y = element_text(colour = "grey20", size = 12),
          text = element_text(size = 19))     
     
> requests_timeperiod %>%
     ggplot(aes(x = Time_Period, y = mean_requests,group=1)) +
     geom_line(color = "darkorchid4") +
     labs(title = "Mean Time_Period Requests",
          subtitle = "Data plotted for each time period",
          y = "Daily Total no.of Requests/Tot.num.of drivers",
          x = "Time_Period") + theme_bw(base_size = 15)     






          
> requests_week_of_year <- df_8 %>%
     group_by(Week_of_Year) %>%
     summarise(means_requests = sum(Total_num_of_requests)/sum(Total_num_of_drivers))

> requests_week_of_year %>%
     ggplot(aes(x = Week_of_Year, y = means_requests,group=1)) +
     geom_line() +geom_point(color = "darkorchid4")+
     labs(title = "Mean week_of_year_Requests",
          subtitle = "Data plotted by week of year",
          y = "Tot.num of Requests/Tot.num of Drivers ",
          x = "Week_of_Year") + theme_bw(base_size = 15)

> df_8$day_Month=as.integer(df_8$day_Month)
> df_8$week_of_Month=ceiling((df_8$day_Month)/7)
> df_8 <- df_8 %>% mutate_if(is.numeric,as.factor)
> df_8$Total_num_of_requests=as.integer(df_8$Total_num_of_requests)
> df_8$Total_num_of_drivers=as.integer(df_8$Total_num_of_drivers)


Average Revenue:
> revenue=group_by(MyData2,geo_hash1, Time_Period)
> rev1=summarize(revenue, Average_Revenue=mean(total))
> head(rev1)
rev1 = as.data.frame(rev1)
df_0 = ddply(rev1,'geo_hash1', plyr::summarise, Time_Period =seq(1, 48))
z2 = merge(rev1,df_0,all.y=TRUE)
write.csv(z2, "data3.csv", na = "0")
> df_rev <- read.csv(file="data3.csv",stringsAsFactors = F,row.names=1)

*Driver Allocation Problem*:
****** Creating matrices for number of requests, expected return and distance***

>no.ofrequests<-matrix(sample(0:4,140,replace=TRUE),ncol=7,byrow=FALSE)
>exp.return<-matrix(sample(10:100,140,replace=TRUE),ncol=7,byrow=FALSE)
>exp.return[which(no.ofrequests == 0)] <- 0
>driver_reqst=matrix(data = 0:1, nrow = 10, ncol = 20)
>vreqs=no.ofrequests[1:20,1]
>driver_reqst[4,7]=0
> driver_reqst[5,8]=1
> driver_reqst[7,8]=1
> driver_reqst[10,9]=0
> driver_reqst[6,9]=0
> driver_reqst[2,11]=0
> driver_reqst[4,11]=0
> driver_reqst[6,11]=0
> driver_reqst[8,11]=0

> driver_reqst[7,20]=1
colSums(driver_reqst)
#ex <- matrix(c(0, 0.5, 0.8, 1, 0, 0.2, 0.5, 0.7, 0.1, 0, 1, 0.3, 1, 0.8, 0.2), 5, 3, byrow = TRUE)
#dist(ex, diag = TRUE, upper = TRUE)
> N=20
> G=20
x=1:20
>Dist_matrix=dist(x,method="euclidean",diag=TRUE,upper = TRUE)

*****Randomly Allocate drivers to geohashes*****:
*****vector of size 1:N, elements of this vector are an integer b/w 1:G****
**** N= number of drivers, G= number of geohashes ******

>x1=seq(1,20)
>dl:driver location
>dl=sample(x1,N)
library(disto)
# create a disto connection 
>dio <- disto(objectname = "Dist_matrix")
>unclass(dio)
>summary(dio)
library(robustbase)
> # quick plots
>plot(dio, type = "dendrogram")
>Ljt=dio[1:20,1]
Ljt
>vRjt=exp.return[1:20,1] (for t=1)
>vRjt
sum=0
Sum=0
w=15
 for (i in 1:N){
 sum=sum(vRjt-(w*Ljt))
 Sum=Sum+sum
 sum=0
 print(Sum)}
 Sum
>dd=as.matrix(Dist_matrix)
> dd[,dl[2]]
> dd[dl[2],]
> for (i in 1:N){
 dm=dd[,dl[i]]
 dl2[i]=which.max(vRjt-(w*dm))}
vreqs[(sort(unique(H[,2])))]<x1[,1]

#driver_reqst=matrix(data = 0:1, nrow = 10, ncol = 20)
#H=cbind(1:nrow(t(vRjt-(w * dd[,dl]))), max.col(t(vRjt-(w*dd[,dl])),'first'))
>for(i in 1:nrow(mat1)){
     if(mat1[i,][1]>mat1[i,][2]){
         print(mat1[i,][1])
     }
**** Retrieving only the passenger requests for timeperiod t=1 and assign 1 if 
requests are greater than 0 in all the geohashes ***
***** Calculating expected profit for all the drivers if requests are greater
than 0****
*** Calculating a frequency table to show the number of allocated drivers
and the available total number of requests in all the geohashes****

>f=no.ofrequests[,1]
>f1=no.ofrequests[,1]
>f[f>0]<-1
>F<-rbind(f)[rep(1,N),]
>BM=t(vRjt-(w*dd[,dl])) * F
>BM[BM<0]<-0
>H=cbind(1:nrow(t(vRjt-(w*dd[,dl]))), max.col(BM),apply(BM,1,max),sample(1:G,N,replace=T))
>H[H[,3]!=0,]
>BMnew<-BM


>Freq=table(H[,2])
>freq=as.matrix(Freq)
>H1=as.matrix(H)
>vreqs=no.ofrequests[1:20,1]
>unique(vreqs[H[,2]])
>vreqs[(sort(unique(H[,2])))]
>vreqs[(sort(unique(H[,2])))]>=freq[,1]
>mat1 <- cbind(vreqs[(sort(unique(H[,2])))], freq, sort(unique(H[,2])))


>which.maxn(H[,2]==mat1[7,][3],n=mat1[6,][1])
>sort(H[,3][which.maxn(H[,2]==18,n=3)],decreasing =TRUE)[1:2]
>which.maxn(H[,2]==18,n=3)
>H[,3][which.maxn(H[,2]==18,n=3)]

***changing the column names***

>colnames(mat1)=c("Total no.of requests","Total no.of drivers","Geohash/Location")
>colnames(H)=c("Driver id","Geohash/Location","Expected Profit")
>colnames(mat1)=NULL
>colnames(H)=NULL


****Driver Allocation by checking if number of requests is less than
the number of allocated drivers, then reassigning the allocation 
for all geohashes****
***Appending the allocated drivers and geohashes to empty vectors 
for easy reference ****

>h=hash()
>x <- list()
>i=1
>y=1
>DA=c()
>GA=c()
>for(i in 1:nrow(mat1)){
               if(mat1[i,][1]<mat1[i,][2]){
                           x1=(mat1[i,][3])
                           cat("Geohash: ", x1,"\n")
                           GA=append(GA,x1)
                           aux=which(H[,2]==mat1[i,][3])
                           aux=aux[which.maxn(H[aux,3],n=mat1[i,][1])]
                           
                           for(y in 1:length(aux)){
                               cat ("Allocated Driver number",y,"is:", aux[[y]], "\n")
                               DA=append(DA,aux[[y]])}
#                           my_list= list(DA,GA)
#                           my_list_of_lists <- append(my_list_of_lists,list(my_list))
#                           x=hash(keys=GA,values=DA)
#                           h = hash().set(h, keys=GA, values=DA)
                           y=list("Geohashes" = GA, "Allocated Drivers"=DA)
                          
                           x=append(x,y)
#                          DA=append(which.maxn(H[,2]==mat1[i,][3],n=mat1[i,][1]))
                           BMnew[DA,]<-0
                           BMnew[,GA]<-0
                           Ht1=cbind(1:nrow(t(vRjt-(w*dd[,dl]))), max.col(BMnew),apply(BMnew,1,max),
                           sample(1:G,N,replace=T))
#                           print(Ht1)
                           Ht1[Ht1[,3]==0,2]=0
#                         Ht1[Ht1[,3]==0,4]=0
                           Ht1[Ht1[,3]!=0,]
                           Ht1[auxe1,2]=mat1[i,][3]
                           Ht1[auxe1,3]=H[auxe1,3]
                           
                           
               }
}

>for(i in 1:nrow(mat1)){
               if(mat1[i,][1]<mat1[i,][2]){
                                        auxe=which(H[,2]==mat1[i,][3])
                                        auxe1=auxe[which.maxn(H[auxe,3],n=mat1[i,][1])]
                                        Ht1[auxe1,2]=mat1[i,][3]
                                        Ht1[auxe1,3]=H[auxe1,3]
               }
}


>x=as.data.frame(Ht1)
>coutx=x %>% group_by(x[,2]) %>% summarize(Count=n())
>countx=as.matrix(coutx)
>countx=cbind(countx,vreqs[countx[,1]])
>DA1=c()
>GA1=c()
> for(i in 1:nrow(countx)){
         if(countx[i,][2]>countx[i,][3]){
         x2=(countx[i,][1])
         GA1=append(GA1,x2)
         aux1=which(Ht1[,2]==countx[i,][1])
         aux1=aux1[which.maxn(Ht1[aux1,3],n=countx[i,][3])]
         for(y in 1:length(aux1)){
         DA1=append(DA1,aux1[[y]])} 
         BMnew[,GA1]<-0
         BMnew[DA1,]<-0
         Ht1a=cbind(1:nrow(t(vRjt-(w*dd[,dl]))), max.col(BMnew),apply(BMnew,1,max),sample(1:G,N,replace=T))
         Ht1a[Ht1a[,3]==0,2]=0
         Ht1a[Ht1a[,3]==0,4]=0
 }
 }



***for 2 time periods:****

>t2=c()
>for(i in 1:ncol(no.ofrequests[,1:2])){
                f=no.ofrequests[,i]
                f[f>0]<-1
                F<-rbind(f)[rep(1,N),]
                BM2=t(exp.return[,i]-(w*dd[,dl])) * F
                BM2[BM2<0]<-0
      H2=cbind(1:nrow(t(exp.return[,i]-(w*dd[,dl]))),max.col(BM2),apply(BM2,1,max),sample(1:G,N,replace=T))
                t2=cbind(t2,H2)
}
>vreqs1=no.ofrequests[,1:2]
>Freq1=table(t2[,2])
>freq1=as.matrix(Freq1)
>Freq2=table(t2[,6])
>freq2=as.matrix(Freq2)
>library(dplyr)                
>ll <- list(vreqs1[,1][(sort(unique(t2[,2])))],freq1,sort(unique(t2[,2])),vreqs1[,2][(sort(unique(t2[,6])))],
>freq2,sort(unique(t2[,6])))
>mat2=lapply(ll, function(x) x[1: max(sapply(ll, length))]) %>% do.call(cbind, .)
>mat2[is.na(mat2)] <- 0

***** Incorporating the rider's waiting time cost to determine how allocations and expected
profit change*********

>dd[cbind(H[,2],H[,4])] ***** to calculate distance between passenger's pickup and drop off 
>DB1=c()
>DB2=c()

>Dest=sample(1:G,N,replace=T)
>for (x in c(0:10)){
      BM=t(vRjt-((w+x)*dd[,dl])) * F
      BM[BM<0]<-0
      H=cbind(1:nrow(t(vRjt-((w+x)*dd[,dl]))), max.col(BM),apply(BM,1,max),Dest)
      H[H[,3]!=0,]
      BMnew<-BM
      Freq=table(H[,2])
      freq=as.matrix(Freq)
      mat1 <- cbind(vreqs[(sort(unique(H[,2])))], freq, sort(unique(H[,2])))
      print(mat1)
      print(H)
      DB=append(DB,sum(H[,3]+x*dd[cbind(H[,2],H[,4])]))
 }
 
>  BM2=t(-((w)*dd[,dl])) * F
#      BM2[BM2<0]<-0
      H2=cbind(1:nrow(t(-((w)*dd[,dl]))), max.col(BM2),vRjt[],Dest)
      H2[H2[,3]!=0,]
      BM2new<-BM2
      Freq2=table(H2[,2])
      freq2=as.matrix(Freq2)
      mat2 <- cbind(vreqs[(sort(unique(H2[,2])))], freq2, sort(unique(H2[,2])))
      print(mat2)
      print(H2)
      DB2=sum(H2[,3])
      
       BM=t(vRjt-((w+x)*dd[,dl])) * F
      BM[BM<0]<-0
      H=cbind(1:nrow(t(vRjt-((w)*dd[,dl]))), max.col(BM),apply(BM,1,max),Dest)
      H[H[,3]!=0,]
      BMnew<-BM
      Freq=table(H[,2])
      freq=as.matrix(Freq)
      mat1 <- cbind(vreqs[(sort(unique(H[,2])))], freq, sort(unique(H[,2])))
      print(mat1)
      print(H)
      DB1=sum(H[,3])
 
> DB=c()
> DB2=c()
> Dest=sample(1:G,N,replace=T)
> for (x in c(0:3)){
          BM=t(vRjt-((w+x)*dd[,dl])) * F
          BM[BM<0]<-0
          H=cbind(1:nrow(t(vRjt-((w+x)*dd[,dl]))), max.col(BM),apply(BM,1,max),Dest)
          H[H[,3]!=0,]
          print (x)
          print(H)
          DB1=sum(H[,3])
          print(DB1)
          BMnew<-BM
          Freq=table(H[,2])
          freq=as.matrix(Freq)
          mat1 <- cbind(vreqs[(sort(unique(H[,2])))], freq, sort(unique(H[,2])))
          print(mat1)
          for(i in 1:nrow(mat1)){
                  if(mat1[i,][1]<mat1[i,][2]){
                           x1=(mat1[i,][3])
                           cat("Geohash: ", x1,"\n")
                           GA=append(GA,x1)
                           aux=which(H[,2]==mat1[i,][3])
                           aux=aux[which.maxn(H[aux,3],n=mat1[i,][1])]
                      
                               for(y in 1:length(aux)){
                                       cat ("Allocated Driver number",y,"is:", aux[[y]], "\n")
                                       DA=append(DA,aux[[y]])}
                           BMnew[DA,]<-0
                           BMnew[,GA]<-0
                           Ht1=cbind(1:nrow(t(vRjt-((w+x)*dd[,dl]))), max.col(BMnew),apply(BMnew,1,max),
                                      +              Dest)
#                          Ht1[Ht1[,3]==0,2]=0
#                          Ht1[Ht1[,3]!=0,]
                           Ht1[aux,2]=mat1[i,][3]
                           Ht1[aux,3]=H[aux,3]
                           length(which(Ht1[,3]==0))
                           Ht1[Ht1[,3]==0,3]=sample(10:100,length(which(Ht1[,3]==0)),replace=T)
                           print(Ht1)
                           
          }
     }
     DB2=append(DB2,sum(Ht1[,3]))
     DB=append(DB,sum(Ht1[,3]+x*dd[cbind(dl,Ht1[,2])]))
    x=(vRjt-((w)*dd[,dl])) 
    x[x<0]=0
    print(x)
  }    
***** Uber driver allocation to passenger requestsusing lpsolve in R ********https://www.r-bloggers.com/uber-assignment-with-lpsolve/*******
***creating passenger’s initial and final locations and driver’sinitial position****

 create_passenger = function(id){
     
     initial.position = sample(50, 2, replace = TRUE)
     final.destination = sample(50, 2, replace = TRUE)
     
     return(list('number' = id, 'initial' = initial.position,
                 'final' = final.destination))
 }
 create_car = function(id){
     
     initial.position = sample(50, 2, replace = TRUE)
     
     return(list('number' = id, 'position' = initial.position))
 }
 distance = function(x,y){
     sum(abs(x-y))
 }
 distance.matrix = function(cars, passengers){
     
     d.matrix = matrix(0, nrow = length(cars), ncol = length(cars))
     
     for (i in 1:length(cars)){
         for (j in 1:length(passengers)){
             d.matrix[i,j] = distance(cars[[i]]$position, passengers[[j]]$initial)
         }
     }
     return(d.matrix)
     
 }
 passengers = lapply(seq(1:10), create_passenger)
 cars = lapply(seq(1:10), create_car)
d.matrix = distance.matrix(cars, passengers)
 opt.allocation = lp.assign(d.matrix)
 passengers.points = sapply(passengers, function(x) x$initial)
 cars.points = sapply(cars, function(x) x$position)
 points = t(cbind(passengers.points, cars.points))
 assignments = apply(opt.allocation$solution, 1, which.max) #checking the assignment for each car
 df1 = data.frame('x.axis' = points[,1],
                  'y.axis' = points[,2],
                  'id' = c(rep('Passenger',10), rep('Car',10)))
 df.assign1 = data.frame('x' = cars.points[1,],
                         'y' = cars.points[2,],
                         'xend' = passengers.points[1,assignments],
                         'yend' = cars.points[2,])
 df.assign2 = data.frame('x' = passengers.points[1,assignments],
                         'y' = cars.points[2,],
                         'xend' = passengers.points[1,assignments],
                         'yend' = passengers.points[2,assignments])
 ggplot(df1, aes(x.axis,y.axis)) + geom_point(aes(color = id, group = id), size = 3) + 
     geom_segment(aes(x = x, y = y, xend = xend, yend = yend), data = df.assign1) +
     geom_segment(aes(x = x, y = y, xend = xend, yend = yend), data = df.assign2,
                  arrow = arrow(length = unit(0.02, "npc"), type = 'closed')) +
     scale_x_continuous(minor_breaks = seq(1, 50, 1)) +
     scale_y_continuous(minor_breaks = seq(1, 50, 1)) +
          ggtitle('Optimal Allocation')

Monte Carlo Simulation:(Passenger Waiting Time)
simulations = function(N, MC) {
     
     ncars = N
     times = matrix(0, nrow = MC, ncol = N)
     
     for (i in 1:MC){
         passengers = lapply(seq(1:10), create_passenger)
         cars = lapply(seq(1:ncars), create_car)
         
         d.matrix = distance.matrix(cars, passengers)
         opt.allocation = lp.assign(d.matrix)
         times[i,] = colSums(opt.allocation$solution*opt.allocation$costs) # waiting time for each passenger
     }
     return(times)
 }
results = lapply(seq(10,30,2), simulations, MC = 500) # MC = 500 just to save some time

df2 = data.frame('WaitingTime' = sapply(results, mean),
                  'LB' = sapply(results, quantile, probs = 0.10),
                  'UB' = sapply(results, quantile, probs = 0.90),
                  'Cars' = seq(10,30,2))
> 
> ggplot(df2, aes(x = Cars)) + geom_line(aes(y = WaitingTime), lwd = 1.2) +
+     geom_ribbon(aes(ymin = LB, ymax = UB), fill = 'blue', alpha = .3)



*****Below code is from another Research Paper*******

t1 <- as.POSIXct("2014-05-05")
t2 <- as.POSIXct("2017-03-07")
t_n_w = floor (as.double(difftime(t2,t1,unit="weeks")))
train_w = floor(t_n_w*2/3)
test_w = t_n_w-train_w
train_r = train_w*7*48
test_r = test_w*7*48

Train set :  98 weeks =98*7*48=32928: Vector!!!
Test set :   51 weeks =50*7*48=16800: Vector!!!

df4 =read.csv('mini.df.1.csv')
df4$X=NULL

#path= ## put your path
#path="C:/Users/yceran/Google Drive/Uber/Baseline_RCode" #windows
#setwd(path)
 
getwd()
library(forecast)


#write.csv(data_train, 'train.csv')

#data=read.csv('data_s.csv')

data=df4$Total_num_of_requests

calsmp=function(n,pred, rd)
{
  s=sum(abs(( pred-rd))/( pred+rd+1))/n
  return(s)
}

demandtable=function(x,li){
  rownames(li[[x]]) <- weekdays(as.Date(4,"1970-01-01",tz="GMT")+0:6)
  colnames(li[[x]])<-colnames(li[[x]], do.NULL = FALSE, prefix = "Period")
  as.table(li[[x]])
}


table_pr=function(m){  
  rownames(m) <- weekdays(as.Date(4,"1970-01-01",tz="GMT")+0:6)
  colnames(m)<-colnames(m, do.NULL = FALSE, prefix = "Period")
  m=as.table(m)
  return(m)
}



calculsum=function(z,np,n,liste){                   
  
  sapply(1:np,function(y) sum(sapply(1:n, function(x)liste[[x]][z,y])))
}


#Function returning predictions using Time-varying Poisson Model

#Input: n1: number of weeks considered in the train set
#       n2:number of weeks considered in the test set
#       n:number of periods in the day ( our case study 48 periods)

#       list_p: List of the historical demand stored 
#       in tables(rows: day of the week/ columns: day Period(our case P=30-->48 period))

#       list_a: List of the demand of the test set stored 
#       in tables(rows: day of the week/ columns: day Period(our case P=30-->48 period))
#       Same order of days  as list_p


#Output: vector of the predicted number of services


poisson_pred=function(n,n1,n2,list_p, list_a){  
  
  
  sum_past=lapply(1:7,function(x) calculsum(x,n,n1,list_p))
  
  sum_past <- table_pr(matrix(unlist(sum_past), ncol =n, byrow = TRUE))
  
  
  p_1=round(sum_past/nbr_week)
  
  #updating the set of the historical demand for each week for the test set
  sum_past_list=lapply(1:(n2-1),function(x) sum_past-list_p[[x]]+list_a[[x]])
  
  poisson_list=lapply(1:n2,function(x) if(x==1){p_1}else{round(sum_past_list[[x-1]]/nbr_week)})
  
  pred_p=unlist(lapply(1:n2, function(x) as.vector(t(poisson_list[[x]]))))
  
  return(pred_p)
  
}




calculwsum=function(n,z,num,w,l){
  sapply(1:n, function(y) round(sum(sapply(1:num, function(x)l[[x]][z,y]*w[num-x+1]))/sum(w[1:num]))
  )
}

#Size of Memory for W.Poisson Model 



#Function returning predictions using Time-varying Poisson Model

#Input: n1: number of weeks considered in the train set
#       n2:number of weeks considered in the test set
#       n:number of periods considred in one day (48 our case)

#       list_p: List of the historical demand stored 
#       in tables(rows: day of the week/ columns: day Period(our case P=30-->48 period))

#       list_a: List of the demand of the test set stored 
#       in tables(rows: day of the week/ columns: day Period(our case P=30-->48 period))
#       Same order of days  as list_p
#       w/num= size of memory considered for W.POISSON Model 
#       Consult the paper Part III.B eq(5)
#Example
alpha=0.4  #user_defined variable


we= sapply(1:20, function(y)alpha*(1-alpha)^(y-1))
num=max(which(we> 0.01))


#Output: vector of the predicted number of services




wpoisson_pred=function(n,n1,n2,num,w,list_p,list_a){  
  
  
  list_p2=lapply(1: num, function(x) list_p[[n1-num+x]])
  
  pdemand_list=append(list_p2,list_a)
  
  
  #updating the set of the historical demand for each week for the test set
  up_pdemand_list=lapply(1:n2, function(x)pdemand_list[x:(num-1+x)])
  
  
  wpoisson_list=lapply(1:n2, function(y) table_pr(matrix(unlist(lapply(1:7,we
                                                                       function(x) calculwsum (n,x,num,w,up_pdemand_list[[y]]))), ncol = n, byrow = TRUE)))
  
  pred_wp=unlist(lapply(1:n2, function(y) as.vector(t(wpoisson_list[[y]]))))
  
  
  return(pred_wp)
  
}



calculaModeloArima<-function(timeseries,th=14*48)
{
  
  #if th<15 days, produce warning
  if (length(timeseries)<th)
  {
    print(length(timeseries))
    print(th)
    print("WARNING: The supplied series has a size smaller than expected !!!")
  }
  
  #Select the model
  fit <- tryCatch(auto.arima(timeseries,allowdrift=FALSE,seasonal = FALSE), error=function(e) e)
  if (is.list(fit))
  {
    arma<-fit$arma
    myOrder<-c(arma[1],arma[6],arma[2])
    if (is.vector(myOrder) && length(myOrder)==3)
    {
      if ((myOrder[1]==4 && myOrder[2]==0 && myOrder[3]==4) || (myOrder[1]==0 && myOrder[2]==0 && myOrder[3]==0) || (myOrder[1]==4 && myOrder[2]==0 && myOrder[3]==3) || (myOrder[1]==3 && myOrder[2]==0 && myOrder[3]==3) || (myOrder[1]==2 && myOrder[2]==1 && myOrder[3]==2) || (myOrder[1]==5 && myOrder[2]==0 && myOrder[3]==4)|| (myOrder[1]==5 && myOrder[2]==0 && myOrder[3]==3) || length(myOrder[myOrder>4])>0)
        myOrder=c(2,0,2)
    }
    else
      myOrder=c(2,0,2)
  }
  else
  {
    print("WARNING: Could not determine the model !!! (P, d, q) = (2.0.2)!!!")
    myOrder=c(2,0,2)
  }
  
  return (myOrder)
}


#calculate_arima_pred : generate one predicted times series value  for a considered period 'per'
# in a considered day 'day', using arima model and 'ndays' as number of day in the training period

#Output=one predicted times series value

#Input= *timeseies=time series values ( contains both train + test values)
#       *ndays:number of days used for the training period/Our case Train 2 weeks = 14 days
#       * day :Considred day  for which we want to get the predictions
#       * n: number of periods in the day / our case P=30 min --> n=48 periods
#       * per: considred period in the day
#       * O: arima order used for the prediction (calculated using calculaModeloArima)

calculate_arima_pred=function(timeseries, ndays,n,day,o,per){
  datapred=timeseries[(per+n*(day-1)):((ndays*n)+(per-1)+n*(day-1))]
  r <- tryCatch(round(predict(arima(datapred,order=o ), n.ahead =1)$pred), error=function(e) e)
  if (is.numeric(r))
  {if(r<0){r=0}else{r=(r)}}else{r=0}
  return(r)
}

#calculate_arima_pred : generate one predicted times series value  for a considered period 'per'
# in a considered day 'day', using arima model and 'ndays' as number of day in the training period

#Output=one predicted times series value

#Input= *timeseies=time series values ( contains both train + test values)
#       *ndays:number of days used for the training period/Our case Train 2 weeks = 14 days
#       * day :Considred day  for which we want to get the predictions
#       * n: number of periods in the day / our case P=30 min --> n=48 periods


calculate_arima_pred_day=function(timeseries, ndays,n,day){
  
  
  ts_train=timeseries[(1+n*(day-1)):((ndays*n)+n*(day-1))]
  o=calculaModeloArima(ts_train)
  
  r=sapply(1:n, function(x) calculate_arima_pred(timeseries, ndays,n,day,o,x))
  return(r)
}


calculensemble=function(H,pr,pred1,pred2,pred3){
  
  rtest1=sapply(1:H, function(y)pred1[(pr-H-1+y)])
  xtest=sapply(1:H, function(y) Demand[(pr-H-1+y)])
  rtest2=sapply(1:H, function(y)pred2[(pr-H-1+y)])
  rtest3=sapply(1:H, function(y)pred3[(pr-H-1+y)])
  
  ro1=sum(abs(rtest1-xtest)/(rtest1+xtest+1))/H
  ro2=sum(abs(rtest2-xtest)/(rtest2+xtest+1))/H
  ro3=sum(abs(rtest3-xtest)/(rtest3+xtest+1))/H
  gama=(1-ro1)+(1-ro2)+(1-ro3)
  r=round((pred1[pr]*(1-ro1)+pred2[pr]*(1-ro2)+pred3[pr]*(1-ro3))/gama)
  return(r)
  
}


#Demand:Test set : last 50 week =50*7*48=16,800: Vector!!!

head(df4)


Demand=data[(train_r+1):(t_n_w*7*48)]
#Create tables for the real Demand 


s=sapply((1:test_w), function(x) Demand[((x-1)*336+1):(x*336)])

l=lapply((1:test_w), function(x) matrix(s[,x],ncol = 48, byrow = TRUE)) 


#list containing demand tables for 50 week of the test period
demand_list=lapply((1:test_w), function(x) demandtable(x,l))



#pastdemand:Train set :  98 week =98*7*48=32928: Vector!!!

pastdemand=data[1:train_r]
#Create tables for the past Demand 
s1=sapply((1:train_w), function(x) pastdemand[((x-1)*336+1):(x*336)])

l1=lapply((1:train_w), function(x) matrix(s1[,x],ncol = 48, byrow = TRUE)) 


demand_list1=lapply((1:train_w), function(x) demandtable(x,l1))

n=48
n1=98
n2=50

pred_p=poisson_pred(n,n1,n2,demand_list1, demand_list)
  
pred_wp=wpoisson_pred(n,n1,n2,num,we,demand_list1, demand_list)

ts=data[(train_r):(t_n_w*7*48)]

pred_a=unlist(lapply((1:train_w), function(x)calculate_arima_pred_day(ts, 14,48,x)))

pred_e=NULL
if (is.null(Demand)==TRUE){
  pred_e[1:8]=0
} else{
  pred_e[1:8]=Demand[1:8]
}

pred_e[9:2688]=sapply(9:2688,function(x) calculensemble(8,x,pred_p,pred_wp,pred_a))


l_res=list(pred_p,pred_wp,pred_a,pred_e)

sMAPE=data.frame(sapply(1:4, function(x) calsmp(2688,l_res[[x]],Demand)))
  


rownames(sMAPE)=c("Poisson","W.Poisson","Arima","ENS")
colnames(sMAPE)=c("sMAPE")


library(knitr)

cat('#', 'sMAPE Table', "\n")
  
cat('\r\n\r\n')
kable(round(sMAPE, digits = 4)*100) 
  


